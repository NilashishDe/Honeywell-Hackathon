{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObwlLqTgQg+tOavv8WiUkQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NilashishDe/Honeywell-Hackathon/blob/main/flightdataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMUyf02wsTLy",
        "outputId": "8d432f22-b1b5-4f61-c214-e036ea50dafc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned 6-9flight.xlsx. Found 384 valid flights.\n",
            "Cleaned 9-12flight.xlsx. Found 391 valid flights.\n",
            "\n",
            "Successfully combined and saved cleaned data to 'cleaned_flight_data.csv'\n",
            "Total valid flights in combined dataset: 775\n",
            "  Flight Number        Date          From                To       Aircraft  \\\n",
            "0                2025-07-25  Mumbai (BOM)  Chandigarh (IXC)  A20N (VT-EXU)   \n",
            "1                2025-07-24  Mumbai (BOM)  Chandigarh (IXC)  A20N (VT-RTJ)   \n",
            "2                2025-07-23  Mumbai (BOM)  Chandigarh (IXC)  A20N (VT-TQB)   \n",
            "3                2025-07-22  Mumbai (BOM)  Chandigarh (IXC)  A20N (VT-RTU)   \n",
            "4                2025-07-21  Mumbai (BOM)  Chandigarh (IXC)  A20N (VT-EXK)   \n",
            "\n",
            "        STD       STA  delay_minutes  is_delayed day_of_week  scheduled_hour  \n",
            "0  06:00:00  08:10:00            4.0           0      Friday               8  \n",
            "1  06:00:00  08:10:00           -9.0           0    Thursday               8  \n",
            "2  06:00:00  08:10:00           13.0           0   Wednesday               8  \n",
            "3  06:00:00  08:10:00           70.0           1     Tuesday               8  \n",
            "4  06:00:00  08:10:00           -9.0           0      Monday               8  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4123803572.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Flight Number'].fillna(method='ffill', inplace=True)\n",
            "/tmp/ipython-input-4123803572.py:20: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df['Flight Number'].fillna(method='ffill', inplace=True)\n",
            "/tmp/ipython-input-4123803572.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Flight Number'].fillna(method='ffill', inplace=True)\n",
            "/tmp/ipython-input-4123803572.py:20: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df['Flight Number'].fillna(method='ffill', inplace=True)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def clean_flight_data(file_path):\n",
        "    \"\"\"\n",
        "    This function takes the path to one of your raw Excel files\n",
        "    and returns a cleaned, structured DataFrame.\n",
        "    \"\"\"\n",
        "    # Use pd.read_excel() - the 'on_bad_lines' argument has been REMOVED.\n",
        "    df = pd.read_excel(\n",
        "        file_path,\n",
        "        header=None, # Treat the first row as data\n",
        "        skiprows=1, # Skip the original header row\n",
        "        names=[\n",
        "            'S.No', 'Flight Number', 'Date', 'From', 'To', 'Aircraft',\n",
        "            'Flight time', 'STD', 'ATD', 'STA', 'col10', 'ATA', 'col12', 'col13'\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # --- Data Cleaning (This part remains the same) ---\n",
        "    df['Flight Number'].fillna(method='ffill', inplace=True)\n",
        "    df.dropna(subset=['Date'], inplace=True)\n",
        "    df.drop(columns=['S.No', 'col10', 'col12', 'col13'], inplace=True)\n",
        "\n",
        "    def clean_ata(time_str):\n",
        "        if isinstance(time_str, str) and 'Landed' in time_str:\n",
        "            time_part = time_str.replace('Landed', '').strip()\n",
        "            try:\n",
        "                return pd.to_datetime(time_part, format='%I:%M %p').strftime('%H:%M:%S')\n",
        "            except (ValueError, TypeError):\n",
        "                return None\n",
        "        elif hasattr(time_str, 'strftime'):\n",
        "             return time_str.strftime('%H:%M:%S')\n",
        "        return time_str\n",
        "\n",
        "    df['ATA_cleaned'] = df['ATA'].apply(clean_ata)\n",
        "\n",
        "    # Ensure time columns are strings before concatenation\n",
        "    df['STA'] = df['STA'].astype(str)\n",
        "    df['ATA_cleaned'] = df['ATA_cleaned'].astype(str)\n",
        "\n",
        "    # Clean the date column to handle potential timestamp objects\n",
        "    df['Date'] = pd.to_datetime(df['Date']).dt.date.astype(str)\n",
        "\n",
        "    df['STA_datetime'] = pd.to_datetime(df['Date'] + ' ' + df['STA'], errors='coerce')\n",
        "    df['ATA_datetime'] = pd.to_datetime(df['Date'] + ' ' + df['ATA_cleaned'], errors='coerce')\n",
        "\n",
        "    df['delay_minutes'] = (df['ATA_datetime'] - df['STA_datetime']).dt.total_seconds() / 60\n",
        "    df['is_delayed'] = df['delay_minutes'].apply(lambda x: 1 if x > 15 else 0)\n",
        "    df['day_of_week'] = df['STA_datetime'].dt.day_name()\n",
        "    df['scheduled_hour'] = df['STA_datetime'].dt.hour\n",
        "\n",
        "    final_df = df[[\n",
        "        'Flight Number', 'Date', 'From', 'To', 'Aircraft', 'STD', 'STA', 'delay_minutes',\n",
        "        'is_delayed', 'day_of_week', 'scheduled_hour'\n",
        "    ]].copy()\n",
        "    final_df.dropna(subset=['delay_minutes', 'To', 'Aircraft'], inplace=True)\n",
        "\n",
        "    print(f\"Cleaned {file_path}. Found {len(final_df)} valid flights.\")\n",
        "    return final_df\n",
        "\n",
        "# --- Main Execution ---\n",
        "if __name__ == '__main__':\n",
        "    # Your Excel filenames\n",
        "    file1 = '6-9flight.xlsx'\n",
        "    file2 = '9-12flight.xlsx'\n",
        "\n",
        "    # Clean both Excel files\n",
        "    df1 = clean_flight_data(file1)\n",
        "    df2 = clean_flight_data(file2)\n",
        "\n",
        "    # Combine them into one big dataset\n",
        "    combined_df = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "    # Save the final, clean dataset to a CSV file\n",
        "    combined_df.to_csv('cleaned_flight_data.csv', index=False)\n",
        "\n",
        "    print(\"\\nSuccessfully combined and saved cleaned data to 'cleaned_flight_data.csv'\")\n",
        "    print(f\"Total valid flights in combined dataset: {len(combined_df)}\")\n",
        "    print(combined_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your cleaned dataset\n",
        "df_clean = pd.read_csv('cleaned_flight_data.csv')\n",
        "\n",
        "# Check for missing values in each column and sum them up\n",
        "missing_values = df_clean.isnull().sum()\n",
        "\n",
        "print(\"Missing values in each column after cleaning:\")\n",
        "print(missing_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOb7bUv0vbSV",
        "outputId": "b4ba8c6a-1067-48c3-8791-dfc9fcf6ffae"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in each column after cleaning:\n",
            "Flight Number     0\n",
            "Date              0\n",
            "From              0\n",
            "To                0\n",
            "Aircraft          0\n",
            "STD               0\n",
            "STA               0\n",
            "delay_minutes     0\n",
            "is_delayed        0\n",
            "day_of_week       0\n",
            "scheduled_hour    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Script: Comparing 5 Models (Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, XGBoost)\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import joblib\n",
        "import warnings\n",
        "\n",
        "# Import all the models we want to compare\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 1. Load the clean data\n",
        "df = pd.read_csv('cleaned_flight_data.csv')\n",
        "\n",
        "# 2. Define Features (X) and Target (y)\n",
        "features = ['From', 'To', 'Aircraft', 'day_of_week', 'scheduled_hour']\n",
        "target = 'is_delayed'\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "\n",
        "# 3. Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4. Set up the preprocessing pipeline for categorical features\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore', drop='first'),\n",
        "         ['From', 'To', 'Aircraft', 'day_of_week'])\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "# 5. Define the models to be evaluated, exactly as per your list\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "}\n",
        "\n",
        "# 6. Loop to train, evaluate, and find the best model using cross-validation\n",
        "results = {}\n",
        "best_model_name = \"\"\n",
        "best_model_score = 0.0\n",
        "\n",
        "print(\"--- Comparing Models using 5-Fold Cross-Validation ---\")\n",
        "for name, model in models.items():\n",
        "    # Create the full pipeline: Preprocessing -> Model\n",
        "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                               ('classifier', model)])\n",
        "\n",
        "    # Use k-fold cross-validation to get a stable performance score\n",
        "    cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
        "    mean_score = cv_scores.mean()\n",
        "    results[name] = mean_score\n",
        "\n",
        "    print(f\"{name} - Cross-Validation Accuracy: {mean_score:.4f}\")\n",
        "\n",
        "    # Keep track of the best model\n",
        "    if mean_score > best_model_score:\n",
        "        best_model_score = mean_score\n",
        "        best_model_name = name\n",
        "\n",
        "print(f\"\\n🏆 Best performing model is: {best_model_name} with a CV score of {best_model_score:.4f}\")\n",
        "\n",
        "# 7. Train the best model on the entire training set and save it\n",
        "best_model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                                      ('classifier', models[best_model_name])])\n",
        "best_model_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 8. Final evaluation on the unseen test data\n",
        "predictions = best_model_pipeline.predict(X_test)\n",
        "print(\"\\n--- Final Report for the Best Model on Unseen Test Data ---\")\n",
        "print(classification_report(y_test, predictions))\n",
        "\n",
        "# 9. Save the champion model\n",
        "joblib.dump(best_model_pipeline, 'flight_delay_model.joblib')\n",
        "print(f\"✅ Successfully saved the winning '{best_model_name}' model to 'flight_delay_model.joblib'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbJdH_zovv6t",
        "outputId": "9630b6ce-f689-45cb-bbf6-39275f5ad29f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Comparing Models using 5-Fold Cross-Validation ---\n",
            "Logistic Regression - Cross-Validation Accuracy: 0.8645\n",
            "Decision Tree - Cross-Validation Accuracy: 0.8306\n",
            "Random Forest - Cross-Validation Accuracy: 0.8806\n",
            "Gradient Boosting - Cross-Validation Accuracy: 0.8629\n",
            "XGBoost - Cross-Validation Accuracy: 0.8790\n",
            "\n",
            "🏆 Best performing model is: Random Forest with a CV score of 0.8806\n",
            "\n",
            "--- Final Report for the Best Model on Unseen Test Data ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.98      0.94       123\n",
            "           1       0.90      0.59      0.72        32\n",
            "\n",
            "    accuracy                           0.90       155\n",
            "   macro avg       0.90      0.79      0.83       155\n",
            "weighted avg       0.90      0.90      0.90       155\n",
            "\n",
            "✅ Successfully saved the winning 'Random Forest' model to 'flight_delay_model.joblib'\n"
          ]
        }
      ]
    }
  ]
}